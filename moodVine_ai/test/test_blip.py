import torch
from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration

# é…ç½®å‚æ•°
MODEL_PATH = "/models_shared/blip-image-captioning-large"
IMAGE_PATH = "../static/1.jpg"


def load_model():
    """åŠ è½½æ¨¡å‹åˆ°GPUå¹¶è¿”å›å¤„ç†å™¨å’Œæ¨¡å‹"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"âœ… æ­£åœ¨ä½¿ç”¨è®¾å¤‡: {device.upper()}")

    # åŠ è½½å¤„ç†å™¨å’Œæ¨¡å‹
    processor = BlipProcessor.from_pretrained(MODEL_PATH)
    model = BlipForConditionalGeneration.from_pretrained(MODEL_PATH).to(device)

    # åŠç²¾åº¦ä¼˜åŒ–ï¼ˆå‡å°‘æ˜¾å­˜å ç”¨ï¼‰
    if device == "cuda":
        model = model.half()

    return processor, model, device


def generate_caption(image_path, processor, model, device):
    """ç”Ÿæˆå›¾åƒæè¿°"""
    try:
        text = "a detailed description of the scene:"
        # åŠ è½½å›¾åƒå¹¶é¢„å¤„ç†
        image = Image.open(image_path).convert("RGB")
        inputs = processor(image, text, return_tensors="pt").to(device)

        # åŠç²¾åº¦è¾“å…¥ï¼ˆéœ€ä¸æ¨¡å‹ç²¾åº¦åŒ¹é…ï¼‰
        if device == "cuda":
            inputs = inputs.to(torch.float16)

        # ç”Ÿæˆæè¿°
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_length=200,
                num_beams=5,  # æŸæœç´¢å¢åŠ å¤šæ ·æ€§
                temperature=0.7  # æ§åˆ¶ç”Ÿæˆéšæœºæ€§
            )

            return processor.decode(outputs[0], skip_special_tokens=True)

    except Exception as e:
        raise RuntimeError(f"ç”Ÿæˆæè¿°å¤±è´¥: {str(e)}")


if __name__ == "__main__":
    try:
        # åˆå§‹åŒ–
        processor, model, device = load_model()

        # ç”Ÿæˆæè¿°
        caption = generate_caption(IMAGE_PATH, processor, model, device)
        print(f"\nğŸ–¼ï¸ å›¾åƒæè¿°: {caption}")

        # æ˜¾å­˜ç›‘æ§
        if device == "cuda":
            print(f"ğŸ”¥ æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated() / 1024 ** 2:.2f} MB")

    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥è·¯å¾„: {IMAGE_PATH}")
    except RuntimeError as e:
        print(f"âŒ è¿è¡Œæ—¶é”™è¯¯: {str(e)}")
        if "CUDA out of memory" in str(e):
            print("ğŸ’¡ å°è¯•: 1. å‡å°å›¾åƒå°ºå¯¸ 2. å…³é—­å…¶ä»–å ç”¨æ˜¾å­˜çš„ç¨‹åº 3. ä½¿ç”¨--no-halfç¦ç”¨åŠç²¾åº¦")
